{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d091f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16068c5",
   "metadata": {},
   "source": [
    "# Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53c735e",
   "metadata": {},
   "source": [
    "A Markov chain is a sequence of random variables, denoted as $\\{X^{(t)}\\}$, where $t = 0, 1, 2, \\dots$. Each $X^{(t)}$ represents a possible state at time $t$ within a state space $\\mathcal{S}$, which includes all possible states the system can occupy. The defining characteristic of a Markov chain is the \\textbf{Markov property}, which states that the next state in the sequence depends only on the current state, not on any prior states. This means that the probability of transitioning to the next state depends solely on the current state, making the process \"memoryless.\"\n",
    "\n",
    "In formal terms, this property can be written as:\n",
    "$$\n",
    "\\mathbb{P}[X^{(t+1)} = j \\mid X^{(t)} = i] = p_{i,j}^{(t)}\n",
    "$$\n",
    "\n",
    "where $p_{i,j}^{(t)}$ denotes the probability of moving from state $i$ to state $j$ at time $t+1$. Now if the Markov chain is irreducible (meaning any state can be reached from any other state) and aperiodic (it does not get \"stuck\" in cycles), then as $t$ grows large, the distribution of $X^{(t)}$ will converge to a stationary distribution.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{1}{n} \\sum_{t=1}^n h(X^{(t)}) \\to \\mathbb{E}_\\pi[h(X)] \\qquad \\qquad (1.46)\n",
    "\\end{align*}\n",
    "\n",
    "This stationary distribution is the target distribution we want to sample from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b61f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c8b10fa",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\documentclass{article}\n",
    "\\usepackage[utf8]{inputenc}\n",
    "\\usepackage[ruled,vlined]{algorithm2e} % Use algorithm2e for \\KwIn, \\eIf, etc.\n",
    "\n",
    "\\begin{document}\n",
    "\\begin{algorithm}[H]\n",
    "\\caption{Metropolis-Hastings Algorithm}\\label{alg:mh}\n",
    "\\KwIn{$f(x)$: Target distribution, $g(x)$: Proposal distribution}\n",
    "\\KwOut{A sequence of samples $X^{(t)}$}\n",
    "\n",
    "\\textbf{Initialize:} Draw a random $x_0$ with $f(x_0) > 0$, set $X^{(0)} = x_0$\\;\n",
    "\n",
    "\\For{$t = 1$ \\textbf{to} $T$}{\n",
    "    \\textbf{1. Generate a candidate $x^*$ from the proposal distribution} $x^* \\sim g(x^* | x^{(t)})$\\;\n",
    "    \\textbf{2. Compute the Metropolis-Hastings ratio:} \\[\n",
    "    r = \\frac{f(x^*) g(x^{(t)} | x^*)}{f(x^{(t)}) g(x^* | x^{(t)})}\n",
    "    \\]\n",
    "    \\eIf{$r \\geq 1$}{\n",
    "        \\textbf{3. Accept:} Set $X^{(t+1)} = x^*$\\;\n",
    "    }{\n",
    "        \\textbf{3. Otherwise:} Draw $u \\sim U(0, 1)$\\;\n",
    "        \\eIf{$u < r$}{\n",
    "            \\textbf{Accept:} Set $X^{(t+1)} = x^*$\\;\n",
    "        }{\n",
    "            \\textbf{Reject:} Set $X^{(t+1)} = x^{(t)}$\\;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\\Return{The sequence $X^{(t)}$}\\;\n",
    "\\end{algorithm}\n",
    "\\end{document}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cb44f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d193b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
